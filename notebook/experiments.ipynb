{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed2155c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "import os \n",
    "os.environ['GROQ_API_KEY']=os.getenv(\"GROQ_API_KEY\")\n",
    "loader = TextLoader(\"../data/info.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=500)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-MiniLM-L3-v2\")\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model_name=\"llama-3.3-70b-versatile\",streaming=True\n",
    ")\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are a smart and knowledgeable AI assistant helping users understand the professional background, projects, skills, and certifications of Katta Sai Pranav Reddy.\n",
    "\n",
    "Use the following context extracted from Pranav's profile and provide a clear, helpful, and detailed answer.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\",\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "# --- 7. RAG Chain ---\n",
    "rag_chain = (\n",
    "    RunnableParallel({\n",
    "        \"context\": retriever,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    })\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0a3106c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer (streaming):\n",
      "Based on the context extracted from Pranav's profile, here are the GitHub repository links of his projects:\n",
      "\n",
      "1. **BigBasket-SmartCart-AI-Assistant-for-BigBasket-Shopping**: https://github.com/ka1817/BigBasket-SmartCart-AI-Assistant-for-BigBasket-Shopping\n",
      "2. **Netflix Customer Churn Prediction – End-to-End ML System**: Unfortunately, the exact GitHub link for this project is not provided in the context. However, it is mentioned as a personal project, and you can try searching for it on GitHub using the project name. \n",
      "\n",
      "Additionally, you can also find Pranav's DockerHub repository for the BigBasket Assistant project here: \n",
      "**pranavreddy123/bigbasket-assistant**: https://hub.docker.com/r/pranavreddy123/bigbasket-assistant"
     ]
    }
   ],
   "source": [
    "# --- 8. Run with streaming ---\n",
    "query = \"Give me Github repo links of projects\"\n",
    "\n",
    "print(\"Answer (streaming):\")\n",
    "for chunk in rag_chain.stream(query):\n",
    "    print(chunk, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7de6a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer (streaming):\n",
      "Based on the provided context, Katta Sai Pranav Reddy has the following real-time experiences:\n",
      "\n",
      "1. **Data Science Intern at Unified Mentor Pvt. Ltd.**: Pranav worked as a Data Science Intern at Unified Mentor Pvt. Ltd. from September 2024 to October 2024. During this period, he:\n",
      "\t* Developed and optimized machine learning models to predict employee attrition.\n",
      "\t* Conducted comprehensive data preprocessing, feature engineering, and exploratory data analysis (EDA) to identify key factors influencing employee turnover.\n",
      "\t* Delivered actionable insights and visualized patterns through dashboards and reports, supporting HR teams in making data-driven decisions.\n",
      "\t* Presented findings to stakeholders, translating complex analytics into clear, strategic recommendations for reducing attrition risk.\n",
      "2. **BigBasket SmartCart – AI-Driven Shopping Assistant**: Pranav worked on the BigBasket SmartCart project from June 2025 to July 2025. This project involved:\n",
      "\t* Developing an AI-driven shopping assistant that can understand and respond to user queries.\n",
      "\t* Creating a conversational interface that can provide personalized product recommendations and answers to user questions.\n",
      "3. **Netflix Churn Prediction**: Pranav worked on a project to predict Netflix user churn based on customer behavior and plan details. This project involved:\n",
      "\t* Developing a machine learning model that can predict user churn.\n",
      "\t* Conducting exploratory data analysis (EDA) to identify key features influencing user churn.\n",
      "\t* Creating a deployment-ready API using FastAPI and Docker.\n",
      "\n",
      "These experiences demonstrate Pranav's hands-on experience in machine learning, data science, and software development, as well as his ability to work on real-world projects and deliver actionable insights to stakeholders."
     ]
    }
   ],
   "source": [
    "query = \"What real time experiences do pranav have\"\n",
    "\n",
    "print(\"Answer (streaming):\")\n",
    "for chunk in rag_chain.stream(query):\n",
    "    print(chunk, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da1ed60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer (streaming):\n",
      "Based on the provided context, Katta Sai Pranav Reddy's 10th class marks are as follows:\n",
      "\n",
      "* **Cumulative Grade Point Average (CGPA): 9.5**\n",
      "* The candidate secured the following grades and grade points in curricular areas:\n",
      "\t+ First Language (Telugu): A1 (Grade Point: 10)\n",
      "\t+ Third Language (English): A1 (Grade Point: 10)\n",
      "\t+ Mathematics: A1 (Grade Point: 10)\n",
      "\t+ Science: A1 (Grade Point: 9)\n",
      "\t+ Social Studies: A1 (Grade Point: 10)\n",
      "\t+ Second Language (Hindi): B1 (Grade Point: 8)\n",
      "\n",
      "Pranav passed the SSC examination held in March 2019."
     ]
    }
   ],
   "source": [
    "query = \"\"\n",
    "\n",
    "print(\"Answer (streaming):\")\n",
    "for chunk in rag_chain.stream(query):\n",
    "    print(chunk, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a7483e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer (streaming):\n",
      "Katta Sai Pranav Reddy deployed the Netflix Churn Prediction project using a containerized deployment via Docker. The project utilizes a production-grade, explainable, and reproducible ML pipeline with CI/CD, experiment tracking (MLflow), and data versioning (DVC).\n",
      "\n",
      "Here's an overview of the deployment architecture:\n",
      "\n",
      "1. **Containerization**: The project uses Docker for containerization, which allows for easy deployment and scalability.\n",
      "2. **FastAPI Interface**: The project exposes a FastAPI interface, which provides a RESTful API for interacting with the model.\n",
      "3. **MLflow Tracking**: The project uses MLflow for experiment tracking, which allows for tracking of experiment metadata, metrics, and parameters.\n",
      "4. **Data Versioning**: The project uses DVC for data versioning, which allows for tracking changes to the data and ensuring reproducibility.\n",
      "5. **CI/CD**: The project uses GitHub Actions for CI/CD, which automates the build, test, and deployment process.\n",
      "\n",
      "The project architecture is as follows:\n",
      "```markdown\n",
      "netflix-churn-prediction/\n",
      "├── data/                     # Raw and processed data\n",
      "├── models/                   # Trained model binaries\n",
      "├── reports/                  # Classification reports & plots\n",
      "├── static/                   # CSS\n",
      "├── templates/                # HTML UI\n",
      "├── src/\n",
      "│   ├── data_ingestion.py     # Load dataset\n",
      "│   ├── data_preprocessing.py # Pipeline for scaling & encoding\n",
      "│   └── model_training.py     # ML training & evaluation\n",
      "├── main.py                   # FastAPI backend\n",
      "├── Dockerfile                # Containerization\n",
      "├── .dvc/                     # DVC for data version control\n",
      "├── .github/workflows/        # CI/CD GitHub Actions\n",
      "└── README.md\n",
      "```\n",
      "The end-to-end ML workflow is as follows:\n",
      "\n",
      "1. **Data Ingestion**: Loads the dataset into a DataFrame and handles errors.\n",
      "2. **Preprocessing**: Preprocesses the data using OneHotEncoding and StandardScaler.\n",
      "3. **Model Training**: Trains the model using RandomForest, GradientBoosting, and SVC, and tunes hyperparameters using GridSearchCV.\n",
      "4. **MLflow Tracking**: Tracks experiment metadata, metrics, and parameters, and stores models and artifacts.\n",
      "5. **Model Deployment**: Deploys the model using Docker and exposes the FastAPI interface.\n",
      "\n",
      "The model performance is evaluated using metrics such as accuracy, F1 score, and ROC AUC, and the best-performing model is selected for deployment."
     ]
    }
   ],
   "source": [
    "query = \"How He Deployed Netflix Churn Prediction Project\"\n",
    "\n",
    "print(\"Answer (streaming):\")\n",
    "for chunk in rag_chain.stream(query):\n",
    "    print(chunk, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "122c5033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The person name is pranav and age is 32\n"
     ]
    }
   ],
   "source": [
    "class Person:\n",
    "    def __init__(self,name='pranav',roll=61):\n",
    "        self.name1=name\n",
    "        self.roll1=roll\n",
    "    def classs(self,age):\n",
    "        print(f\"The person name is {self.name1} and age is {age}\")\n",
    "\n",
    "a=Person()\n",
    "a.classs(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953e5668",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
